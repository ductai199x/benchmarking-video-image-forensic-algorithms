{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms.functional import resize\n",
    "from torchvision.io import read_image, write_png\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    \"video_adv_splc\",\n",
    "    \"video_vis_aug\",\n",
    "    \"video_invis_aug\",\n",
    "    \"video_sham_adobe\",\n",
    "    \"video_e2fgvi_davis\",\n",
    "    \"videomatting\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \".\"\n",
    "loc_result_dir = f\"{root_dir}/loc_comparisons\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in datasets:\n",
    "    if not os.path.exists(f\"{loc_result_dir}/{d}\"):\n",
    "        os.makedirs(f\"{loc_result_dir}/{d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_vs_ds_path = {\n",
    "    \"video_adv_splc\": \"/media/nas2/graph_sim_data/video_advanced_splicing/test\",\n",
    "    \"video_vis_aug\": \"/media/nas2/graph_sim_data/video_visible_aug/test\",\n",
    "    \"video_invis_aug\": \"/media/nas2/graph_sim_data/video_invisible_aug/test\",\n",
    "    \"video_sham_adobe\": \"/media/nas2/Datasets/VideoSham-adobe-research/extracted_frames_ge_1920x1080\",\n",
    "    \"video_e2fgvi_davis\": \"/media/nas2/Tai/13-e2fgvi-video-inpainting/ds_1920x1080\",\n",
    "    \"videomatting\": \"/media/nas2/Datasets/VideoMatting/data/dataset\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_vs_samples = {\n",
    "    \"video_adv_splc\": [\n",
    "        \"manip_05798\",\n",
    "        \"manip_04226\",\n",
    "        \"manip_06094\",\n",
    "        \"manip_06575\",\n",
    "        \"manip_06547\",\n",
    "        \"manip_04821\",\n",
    "        \"manip_06826\",\n",
    "        \"manip_04981\",\n",
    "        \"manip_06815\",\n",
    "        \"manip_08303\",\n",
    "    ],\n",
    "    \"video_vis_aug\": [\n",
    "        \"manip_05798\",\n",
    "        \"manip_06475\",\n",
    "        \"manip_07971\",\n",
    "        \"manip_06769\",\n",
    "        \"manip_04630\",\n",
    "        \"manip_08394\",\n",
    "        \"manip_07378\",\n",
    "        \"manip_04333\",\n",
    "        \"manip_06848\",\n",
    "        \"manip_04831\",\n",
    "        \"manip_07085\",\n",
    "    ],\n",
    "    \"video_invis_aug\": [\n",
    "        \"manip_07143\",\n",
    "        \"manip_08009\",\n",
    "        \"manip_06398\",\n",
    "        \"manip_05589\",\n",
    "        \"manip_04427\",\n",
    "        \"manip_05028\",\n",
    "        \"manip_07956\",\n",
    "        \"manip_08294\",\n",
    "        \"manip_05499\",\n",
    "        \"manip_08120\",\n",
    "        \"manip_06038\",\n",
    "    ],\n",
    "    \"video_sham_adobe\": [\n",
    "        \"attack4/manip_4176_0219\",\n",
    "        \"attack4/manip_1044_0088\",\n",
    "        \"attack4/manip_4002_0082\",\n",
    "        \"attack4/manip_4002_0060\",\n",
    "        \"attack1/manip_0098_0138\",\n",
    "        \"attack1/manip_0108_0046\",\n",
    "        \"attack1/manip_0102_0044\",\n",
    "        \"attack1/manip_0102_0046\",\n",
    "        \"attack2/manip_0090_0023\",\n",
    "        \"attack2/manip_0087_0140\",\n",
    "        \"attack2/manip_0084_0280\",\n",
    "    ],\n",
    "    \"video_e2fgvi_davis\": [\n",
    "        \"manip_hockey_054\",\n",
    "        \"manip_schoolgirls_013\",\n",
    "        \"manip_paragliding_046\",\n",
    "        \"manip_horsejump-low_048\",\n",
    "        \"manip_bmx-trees_014\",\n",
    "        \"manip_bmx-bumps_085\",\n",
    "        \"manip_boat_008\",\n",
    "        \"manip_scooter-gray_063\",\n",
    "        \"manip_motorbike_025\",\n",
    "        \"manip_tractor-sand_006\",\n",
    "        \"manip_breakdance_066\",\n",
    "    ],\n",
    "    \"videomatting\": [\n",
    "        \"artem_manip_0138\",\n",
    "        \"artem_manip_0149\",\n",
    "        \"rain_manip_0043\",\n",
    "        \"snow_manip_0129\",\n",
    "        \"snow_manip_0038\",\n",
    "        \"slava_manip_0072\",\n",
    "        \"vitaliy_manip_0055\",\n",
    "        \"concert_manip_0038\",\n",
    "        \"concert_manip_0152\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = [\n",
    "    \"video_transformer\", #0\n",
    "    \"fsg\", #1\n",
    "    \"exif\", #2\n",
    "    \"noiseprint\", #3\n",
    "    \"mvss\", #4\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_transformer videomatting\n"
     ]
    }
   ],
   "source": [
    "arch_choice = architectures[0]\n",
    "ds_choice = datasets[5]\n",
    "print(arch_choice, ds_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_samples = [f\"{ds_vs_ds_path[ds_choice]}/{s}\" for s in ds_vs_samples[ds_choice]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure these files exists:\n",
    "for s in eval_samples:\n",
    "    if not os.path.exists(f\"{s}.png\"):\n",
    "        raise FileNotFoundError(f\"{s}.png\")\n",
    "    if not os.path.exists(f\"{s}.mask\"):\n",
    "        raise FileNotFoundError(f\"{s}.mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from evaluate_model import get_model\n",
    "\n",
    "if arch_choice == \"video_transformer\":\n",
    "    from models.video_transformer.patch_predictions import PatchPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(arch_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6be12fc2e74429b1412a14b73aa69b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sample_name in tqdm(eval_samples):\n",
    "    sample_path = f\"{sample_name}.png\"\n",
    "    sample_gt_mask = f\"{sample_name}.mask\"\n",
    "    sample_folder, sample_basename = os.path.split(os.path.abspath(sample_path))\n",
    "    sample_filename, sample_extension = os.path.splitext(sample_basename)\n",
    "\n",
    "    # sample = resize(read_image(sample_path), [1080, 1920])\n",
    "    sample = Image.open(sample_path, mode=\"r\")\n",
    "    sample = to_tensor(sample) * 255\n",
    "    sample = resize(sample[0:3].to(torch.uint8), [1080, 1920])\n",
    "\n",
    "    gt_mask = read_image(sample_gt_mask)\n",
    "    if gt_mask.max() < 255:\n",
    "        gt_mask[gt_mask > 0] = 255\n",
    "\n",
    "    det, pred_mask = model(sample.unsqueeze(0).float())\n",
    "    det, pred_mask = det.detach().cpu(), pred_mask.detach().cpu()\n",
    "    if arch_choice == \"video_transformer\":\n",
    "        from models.video_transformer.patch_predictions import PatchPredictions\n",
    "        patch_pred_class = PatchPredictions(pred_mask, model.patch_size, model.img_size, min_thresh=0.1, max_num_regions=2, final_thresh=0.20)\n",
    "        pred_mask = patch_pred_class.get_pixel_preds()\n",
    "\n",
    "    if len(pred_mask.shape) < 3:\n",
    "        pred_mask = (pred_mask.unsqueeze(0) * 255).to(torch.uint8)\n",
    "    else:\n",
    "        pred_mask = (pred_mask * 255).to(torch.uint8)\n",
    "    \n",
    "    write_png(sample, f\"{loc_result_dir}/{ds_choice}/{arch_choice}_{sample_filename}.png\", 0)\n",
    "    write_png(gt_mask, f\"{loc_result_dir}/{ds_choice}/{arch_choice}_{sample_filename}_gt_mask.png\", 0)\n",
    "    write_png(pred_mask, f\"{loc_result_dir}/{ds_choice}/{arch_choice}_{sample_filename}_pred_mask.png\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(pred_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_mask.sum() / 255"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('pyt_tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0421650a8a5845f713c56c3ba4f436fc22593ad99b656f8436ea71c2ab26d6c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
