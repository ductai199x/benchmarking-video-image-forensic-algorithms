{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms.functional import resize\n",
    "from torchvision.io import read_image, write_png\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_vs_ds_path = {\n",
    "    \"video_adv_splc\": \"/media/nas2/graph_sim_data/video_advanced_splicing/test\",\n",
    "    \"video_vis_aug\": \"/media/nas2/graph_sim_data/video_visible_aug/test\",\n",
    "    \"video_invis_aug\": \"/media/nas2/graph_sim_data/video_invisible_aug/test\",\n",
    "    \"video_sham_adobe\": \"/media/nas2/Datasets/VideoSham-adobe-research/extracted_frames_ge_1920x1080\",\n",
    "    \"video_e2fgvi_davis\": \"/media/nas2/Tai/13-e2fgvi-video-inpainting/ds_1920x1080\",\n",
    "    \"videomatting\": \"/media/nas2/Datasets/VideoMatting/data/dataset\",\n",
    "    \"deepfake\": \"/media/nas2/deepfakes/cvpr/dataset\",\n",
    "    \"deepfake_not_working\": \"/media/nas2/deepfakes/cvpr/not_working_examples\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_vs_samples = {\n",
    "    \"video_adv_splc\": [\n",
    "        \"manip_05798\",\n",
    "        \"manip_04226\",\n",
    "        \"manip_06094\",\n",
    "        \"manip_06575\",\n",
    "        \"manip_06547\",\n",
    "        \"manip_04821\",\n",
    "        \"manip_06826\",\n",
    "        \"manip_04981\",\n",
    "        \"manip_06815\",\n",
    "        \"manip_08303\",\n",
    "    ],\n",
    "    \"video_vis_aug\": [\n",
    "        \"manip_05798\",\n",
    "        \"manip_06475\",\n",
    "        \"manip_07971\",\n",
    "        \"manip_06769\",\n",
    "        \"manip_04630\",\n",
    "        \"manip_08394\",\n",
    "        \"manip_07378\",\n",
    "        \"manip_04333\",\n",
    "        \"manip_06848\",\n",
    "        \"manip_04831\",\n",
    "        \"manip_07085\",\n",
    "    ],\n",
    "    \"video_invis_aug\": [\n",
    "        \"manip_07143\",\n",
    "        \"manip_08009\",\n",
    "        \"manip_06398\",\n",
    "        \"manip_05589\",\n",
    "        \"manip_04427\",\n",
    "        \"manip_05028\",\n",
    "        \"manip_07956\",\n",
    "        \"manip_08294\",\n",
    "        \"manip_05499\",\n",
    "        \"manip_08120\",\n",
    "        \"manip_06038\",\n",
    "    ],\n",
    "    \"video_sham_adobe\": [\n",
    "        \"attack4/manip_4176_0219\",\n",
    "        \"attack4/manip_1044_0088\",\n",
    "        \"attack4/manip_4002_0082\",\n",
    "        \"attack4/manip_4002_0060\",\n",
    "        \"attack1/manip_0098_0138\",\n",
    "        \"attack1/manip_0108_0046\",\n",
    "        \"attack1/manip_0102_0044\",\n",
    "        \"attack1/manip_0102_0046\",\n",
    "        \"attack2/manip_0090_0023\",\n",
    "        \"attack2/manip_0087_0140\",\n",
    "        \"attack2/manip_0084_0280\",\n",
    "        \"attack3/manip_1050_0151\",\n",
    "        \"attack3/manip_1050_0244\",\n",
    "        \"attack1/manip_4143_0105\",\n",
    "        \"attack1/manip_4143_0213\",\n",
    "    ],\n",
    "    \"video_e2fgvi_davis\": [\n",
    "        \"manip_schoolgirls_013\",\n",
    "        \"manip_paragliding_046\",\n",
    "        \"manip_horsejump-low_048\",\n",
    "        \"manip_motorbike_025\",\n",
    "        \"manip_breakdance_066\",\n",
    "        \"manip_scooter-gray_068\",\n",
    "        \"manip_scooter-gray_039\",\n",
    "        \"manip_scooter-gray_022\",\n",
    "        \"manip_tractor-sand_029\",\n",
    "        \"manip_tractor-sand_035\",\n",
    "        \"manip_tractor-sand_012\",\n",
    "        \"manip_hockey_033\",\n",
    "        \"manip_hockey_032\",\n",
    "        \"manip_hockey_067\",\n",
    "        \"manip_boat_024\",\n",
    "        \"manip_boat_062\",\n",
    "        \"manip_boat_061\",\n",
    "        \"manip_bmx-trees_031\",\n",
    "        \"manip_bmx-trees_032\",\n",
    "        \"manip_bmx-trees_016\",\n",
    "        \"manip_bmx-bumps_011\",\n",
    "\n",
    "    ],\n",
    "    \"videomatting\": [\n",
    "        \"artem_manip_0138\",\n",
    "        \"artem_manip_0149\",\n",
    "        \"rain_manip_0043\",\n",
    "        \"snow_manip_0129\",\n",
    "        \"snow_manip_0038\",\n",
    "        \"slava_manip_0072\",\n",
    "        \"vitaliy_manip_0055\",\n",
    "        \"concert_manip_0038\",\n",
    "        \"concert_manip_0152\",\n",
    "    ],\n",
    "    \"deepfake\": [\n",
    "        \"manip_Zella-Rena_0000\",\n",
    "        \"manip_Zella-Rena_0017\",\n",
    "        \"manip_Ruelle-Leah_0019\",\n",
    "        \"manip_Ella-Katie_0023\",\n",
    "        \"manip_Nicki-Latto_0008\",\n",
    "        \"manip_Nicki-Latto_0024\",\n",
    "        \"manip_Marina-Madison_0022\",\n",
    "        \"manip_Ed-24KGold_0002\",\n",
    "        \"manip_Doja-Kylie_0004\",\n",
    "        \"manip_Selena-Tay_0000\",\n",
    "    ],\n",
    "    \"deepfake_not_working\": [\n",
    "        \"manip_Kanye-Kevin_0016\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \".\"\n",
    "loc_result_dir = f\"{root_dir}/loc_comparisons\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    \"video_adv_splc\", #0\n",
    "    \"video_vis_aug\", #1\n",
    "    \"video_invis_aug\", #2\n",
    "    \"video_sham_adobe\", #3\n",
    "    \"video_e2fgvi_davis\", #4\n",
    "    \"videomatting\", #5\n",
    "    \"deepfake\", #6\n",
    "    \"deepfake_not_working\", #7\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = [\n",
    "    \"video_transformer\", #0\n",
    "    \"fsg\", #1\n",
    "    \"exif\", #2\n",
    "    \"noiseprint\", #3\n",
    "    \"mvss\", #4\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_choice = architectures[4]\n",
    "ds_choice = datasets[3]\n",
    "print(arch_choice, ds_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in datasets:\n",
    "    if not os.path.exists(f\"{loc_result_dir}/{d}\"):\n",
    "        os.makedirs(f\"{loc_result_dir}/{d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_samples = [f\"{ds_vs_ds_path[ds_choice]}/{s}\" for s in ds_vs_samples[ds_choice]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure these files exists:\n",
    "for s in eval_samples:\n",
    "    if not os.path.exists(f\"{s}.png\"):\n",
    "        raise FileNotFoundError(f\"{s}.png\")\n",
    "    if not os.path.exists(f\"{s}.mask\"):\n",
    "        raise FileNotFoundError(f\"{s}.mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_model import get_model\n",
    "\n",
    "if arch_choice == \"video_transformer\":\n",
    "    from models.video_transformer.patch_predictions import PatchPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(arch_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.cuda()\n",
    "# for i in tqdm(range(1000)):\n",
    "#     model(torch.randn(1,3,1080,1920).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_name in tqdm(eval_samples):\n",
    "    sample_path = f\"{sample_name}.png\"\n",
    "    sample_gt_mask = f\"{sample_name}.mask\"\n",
    "    sample_folder, sample_basename = os.path.split(os.path.abspath(sample_path))\n",
    "    sample_filename, sample_extension = os.path.splitext(sample_basename)\n",
    "\n",
    "    # sample = resize(read_image(sample_path), [1080, 1920])\n",
    "    sample = Image.open(sample_path, mode=\"r\")\n",
    "    sample = to_tensor(sample) * 255\n",
    "    sample = resize(sample[0:3].to(torch.uint8), [1080, 1920])\n",
    "\n",
    "    gt_mask = read_image(sample_gt_mask)\n",
    "    if gt_mask.max() < 255:\n",
    "        gt_mask[gt_mask > 0] = 255\n",
    "\n",
    "    det, pred_mask = model(sample.unsqueeze(0).float())\n",
    "    det, pred_mask = det.detach().cpu(), pred_mask.detach().cpu()\n",
    "    if arch_choice == \"video_transformer\":\n",
    "        from models.video_transformer.patch_predictions import PatchPredictions\n",
    "        patch_pred_class = PatchPredictions(pred_mask, model.patch_size, model.img_size, min_thresh=0.1, max_num_regions=3, final_thresh=0.26)\n",
    "        pred_mask = patch_pred_class.get_pixel_preds()\n",
    "\n",
    "    if len(pred_mask.shape) < 3:\n",
    "        pred_mask = (pred_mask.unsqueeze(0) * 255).to(torch.uint8)\n",
    "    else:\n",
    "        pred_mask = (pred_mask * 255).to(torch.uint8)\n",
    "    \n",
    "    if arch_choice == \"video_transformer\":\n",
    "        write_png(sample, f\"{loc_result_dir}/{ds_choice}/{arch_choice}_{sample_filename}.png\", 0)\n",
    "        write_png(gt_mask, f\"{loc_result_dir}/{ds_choice}/{arch_choice}_{sample_filename}_gt_mask.png\", 0)\n",
    "    write_png(pred_mask, f\"{loc_result_dir}/{ds_choice}/{arch_choice}_{sample_filename}_pred_mask.png\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(pred_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_mask.sum() / 255"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('pyt_tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0421650a8a5845f713c56c3ba4f436fc22593ad99b656f8436ea71c2ab26d6c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
