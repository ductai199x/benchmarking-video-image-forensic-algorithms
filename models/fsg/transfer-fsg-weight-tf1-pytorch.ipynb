{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For some setups its neccessary to allow tensorflow to allocate gpu memory\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .tf1_model_code.mislnet_model import prefeat_CompareNet_v1, MISLNet128 as MISLNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_weights_restore = '/home/tai/1-workdir/3-owen-forensic-graph/models/cam_128/-30' #path to model CNN weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off eager execution\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "# reset tf\n",
    "tf.compat.v1.reset_default_graph()\n",
    "# PLACE HOLDERS\n",
    "x = tf.compat.v1.placeholder(tf.float32, shape=[None, 128, 128, 3], name=\"input_data\")\n",
    "f1 = tf.compat.v1.placeholder(tf.float32, shape=[None, 200], name=\"feature1\")\n",
    "f2 = tf.compat.v1.placeholder(tf.float32, shape=[None, 200], name=\"feature2\")\n",
    "MISL_phase = tf.compat.v1.placeholder(tf.bool, name=\"phase\")\n",
    "\n",
    "mislnet_feats = MISLNet(x, MISL_phase, nprefilt=6)\n",
    "mislnet_compare = prefeat_CompareNet_v1(f1, f2)\n",
    "\n",
    "mislnet_restore = tf.compat.v1.train.Saver()\n",
    "\n",
    "tf1_var_val = {}\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    mislnet_restore.restore(sess, f_weights_restore)  # load pretrained network\n",
    "    vars = [var for var in tf.compat.v1.global_variables() if ('MISLNet' in var.name or 'CompareNet' in var.name)]\n",
    "    print(vars) #some infos about variables...\n",
    "    vars_vals = sess.run(vars)\n",
    "    for var, val in zip(vars, vars_vals):\n",
    "        # print(\"var: {}, value: {}\".format(var.name, val))\n",
    "        tf1_var_val[var.name] = {\n",
    "            \"shape\": var.shape.as_list(),\n",
    "            \"value\": val,\n",
    "        }\n",
    "\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MISLNet(torch.nn.Module):\n",
    "    def __init__(self, num_pre_filters=6):\n",
    "        super().__init__()\n",
    "        self.weights_cstr = torch.nn.Parameter(torch.randn(num_pre_filters, 3, 5, 5))\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(num_pre_filters, 96, kernel_size=7, stride=2, padding=\"valid\")\n",
    "        self.bn1 = torch.nn.BatchNorm2d(96, momentum=0.99, eps=0.0001)\n",
    "        self.tanh1 = torch.nn.Tanh()\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size=(3, 3), stride=2)\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(96, 64, kernel_size=5, stride=1, padding=\"same\")\n",
    "        self.bn2 = torch.nn.BatchNorm2d(64, momentum=0.99, eps=0.0001)\n",
    "        self.tanh2 = torch.nn.Tanh()\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size=(3, 3), stride=2)\n",
    "\n",
    "        self.conv3 = torch.nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=\"same\")\n",
    "        self.bn3 = torch.nn.BatchNorm2d(64, momentum=0.99, eps=0.0001)\n",
    "        self.tanh3 = torch.nn.Tanh()\n",
    "        self.maxpool3 = torch.nn.MaxPool2d(kernel_size=(3, 3), stride=2)\n",
    "\n",
    "        self.conv4 = torch.nn.Conv2d(64, 128, kernel_size=1, stride=1, padding=\"same\")\n",
    "        self.bn4 = torch.nn.BatchNorm2d(128, momentum=0.99, eps=0.0001)\n",
    "        self.tanh4 = torch.nn.Tanh()\n",
    "        self.maxpool4 = torch.nn.MaxPool2d(kernel_size=(3, 3), stride=2)\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(2 * 2 * 128, 200)\n",
    "        self.tanh_fc1 = torch.nn.Tanh()\n",
    "        self.fc2 = torch.nn.Linear(200, 200)\n",
    "        self.tanh_fc2 = torch.nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        constr_conv = F.conv2d(x, self.weights_cstr, padding=\"valid\")\n",
    "        constr_conv = F.pad(constr_conv, (2, 3, 2, 3))\n",
    "        \n",
    "        conv1_out = self.maxpool1(self.tanh1(self.bn1(self.conv1(constr_conv))))\n",
    "        conv2_out = self.maxpool2(self.tanh2(self.bn2(self.conv2(conv1_out))))\n",
    "        conv3_out = self.maxpool3(self.tanh3(self.bn3(self.conv3(conv2_out))))\n",
    "        conv4_out = self.maxpool4(self.tanh4(self.bn4(self.conv4(conv3_out))))\n",
    "\n",
    "        # tf reshape has differerent order.\n",
    "        conv4_out = conv4_out.permute(0, 2, 3, 1)\n",
    "        conv4_out = conv4_out.flatten(1, -1)\n",
    "\n",
    "        dense1_out = self.tanh_fc1(self.fc1(conv4_out))\n",
    "        dense2_out = self.tanh_fc2(self.fc2(dense1_out))\n",
    "\n",
    "        return dense2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompareNet(torch.nn.Module):\n",
    "    def __init__(self, input_dim=200, map1_dim=2048, map2_dim=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(input_dim, map1_dim)\n",
    "        self.relu_fc1 = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(map1_dim*3, map2_dim)\n",
    "        self.relu_fc2 = torch.nn.ReLU()\n",
    "        self.fc3 = torch.nn.Linear(map2_dim, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1, x2 = x\n",
    "        m1_x1 = self.relu_fc1(self.fc1(x1))\n",
    "        m1_x2 = self.relu_fc1(self.fc1(x2))\n",
    "\n",
    "        x1x2_mult = m1_x1 * m1_x2\n",
    "        x1x2_concat = torch.concat([m1_x1, x1x2_mult, m1_x2], dim=1)\n",
    "\n",
    "        m2 = self.relu_fc2(self.fc2(x1x2_concat))\n",
    "        out = self.fc3(m2)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSG(torch.nn.Module):\n",
    "    def __init__(self, num_pre_filters=6, input_dim=200, map1_dim=2048, map2_dim=64):\n",
    "        super().__init__()\n",
    "        self.mislnet = MISLNet(num_pre_filters)\n",
    "        self.comparenet = CompareNet(input_dim, map1_dim, map2_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1, x2 = x\n",
    "\n",
    "        x1 = self.mislnet(x1)\n",
    "        x2 = self.mislnet(x2)\n",
    "\n",
    "        out = self.comparenet([x1, x2])\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsg = FSG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(fsg.state_dict().keys())\n",
    "# list(tf1_var_val.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "fsg_state_dict = copy.deepcopy((fsg.state_dict()))\n",
    "for key in list(fsg_state_dict.keys()):\n",
    "    if 'num_batches_tracked' in key:\n",
    "        del fsg_state_dict[key]\n",
    "fsg_torch_to_tf1_state_dict_key_mapping = dict(zip(list(fsg_state_dict.keys()), list(tf1_var_val.keys())))\n",
    "fsg_torch_to_tf1_state_dict_key_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsg_torch_state_dict = OrderedDict()\n",
    "for torch_key, tf1_key in fsg_torch_to_tf1_state_dict_key_mapping.items():\n",
    "    torch_shape = list(fsg.state_dict()[torch_key].shape)\n",
    "    tf1_shape = list(tf1_var_val[tf1_key][\"value\"].shape)\n",
    "\n",
    "    perm_tf1_to_torch = list(range(len(tf1_shape)))\n",
    "    perm_tf1_to_torch.reverse()\n",
    "\n",
    "    tf1_val = torch.from_numpy(tf1_var_val[tf1_key][\"value\"])\n",
    "\n",
    "    if len(re.findall(r\"conv\\d+\\.weight\", torch_key)) > 0:\n",
    "        tf1_val = tf1_val.permute(3, 2, 0, 1)\n",
    "    elif len(re.findall(r\"fc\\d+\\.weight\", torch_key)) > 0:\n",
    "        tf1_val = tf1_val.permute(1, 0)\n",
    "    elif \"weights_cstr\" in torch_key:\n",
    "        tf1_val = tf1_val.permute(3, 2, 0, 1)\n",
    "\n",
    "    fsg_torch_state_dict[torch_key] = tf1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsg.load_state_dict(fsg_torch_state_dict)\n",
    "fsg = fsg.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"test_images/img_demo/splicing-01.TIF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_plt = plt.imread(img_path)[:,:,:3]\n",
    "plt.imshow(img_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.tensor(img_plt).permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size, stride = 128, 128-96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = img.unfold(1, kernel_size, stride).unfold(2, kernel_size, stride).permute(1, 2, 0, 3, 4)\n",
    "patches = patches.contiguous().view(-1, 3, kernel_size, kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_fn(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx : min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_features = []\n",
    "fsg = fsg.cuda()\n",
    "for batch in tqdm(batch_fn(patches, 128)):\n",
    "    batch = batch.float().cuda()\n",
    "    feats = fsg.mislnet(batch).detach().cpu()\n",
    "    patches_features.append(feats)\n",
    "patches_features = torch.vstack(patches_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_cart_prod = torch.cartesian_prod(torch.arange(patches.shape[0]), torch.arange(patches.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_sim_score = patches_features[patch_cart_prod]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_sim_scores = []\n",
    "for batch in tqdm(batch_fn(patches_sim_score, 256)):\n",
    "    batch = batch.permute(1,0,2).float().cuda()\n",
    "    scores = torch.nn.functional.softmax(fsg.comparenet(batch), dim=1).detach().cpu()\n",
    "    patches_sim_scores.append(scores)\n",
    "patches_sim_scores = torch.vstack(patches_sim_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mat = patches_sim_scores[:, 1].reshape(len(patches), len(patches))\n",
    "sim_mat = 0.5*(sim_mat + sim_mat.T)\n",
    "sim_mat.fill_diagonal_(1.0)\n",
    "sim_mat = sim_mat.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.spectral_utils import laplacian, eigap01, spectral_cluster\n",
    "from src.localization import PatchLocalization, pixel_loc_from_patch_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = laplacian(sim_mat) #laplacian matrix\n",
    "gap = eigap01(L) #spectral gap\n",
    "print(f'Spectral Gap = {gap:.2f}')\n",
    "\n",
    "normL = laplacian(sim_mat, laplacian_type='sym') #normalized laplacian matrix\n",
    "normgap = eigap01(normL) #normalized spectral gap\n",
    "print(f'Normalized Spectral Gap = {normgap:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inds = torch.arange(img_plt.shape[1]).unfold(0, kernel_size, stride)[:, 0]\n",
    "y_inds = torch.arange(img_plt.shape[0]).unfold(0, kernel_size, stride)[:, 0]\n",
    "xy_inds = [\n",
    "    (ii, jj)\n",
    "    for jj in y_inds\n",
    "    for ii in x_inds\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = spectral_cluster(normL)\n",
    "\n",
    "pat_loc = PatchLocalization(\n",
    "    inds = xy_inds, \n",
    "    patch_size = 128,\n",
    "    prediction = ~prediction)\n",
    "f = pat_loc.plot_heatmap(image=img_plt, label=0)\n",
    "#here we flip the label for easier visualization..\n",
    "#note the label=0 in the line above\n",
    "#and the ~pat_loc.prediction in the line below\n",
    "pix_loc = pixel_loc_from_patch_pred(\n",
    "    prediction=~pat_loc.prediction,\n",
    "    inds = xy_inds,\n",
    "    patch_size = 128,\n",
    "    image_shape = img_plt.shape[:2],\n",
    "    threshold = 0.45\n",
    ")\n",
    "\n",
    "pix_loc.plot(image=img_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(fsg.state_dict(), \"fsg_image_pytorch_from_tf1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fsg_reload = FSG()\n",
    "# fsg_reload.load_state_dict(torch.load(\"fsg_image_pytorch_from_tf1.pt\"))\n",
    "# fsg_reload = fsg_reload.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "batch_size = 2\n",
    "x1 = torch.randint(0, 255, (batch_size, 3, 128, 128)).float()\n",
    "x2 = torch.randint(0, 255, (batch_size, 3, 128, 128)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fsg([patches[0].float().unsqueeze(0), patches[1].float().unsqueeze(0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fsg_reload([x1, x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    mislnet_restore.restore(sess, f_weights_restore)  # load pretrained network\n",
    "    tf1_x1 = sess.run(mislnet_feats, feed_dict={x: x1.permute(0, 2, 3, 1), MISL_phase: False})\n",
    "    tf1_x2 = sess.run(mislnet_feats, feed_dict={x: x2.permute(0, 2, 3, 1), MISL_phase: False})\n",
    "    tf1_out = sess.run(mislnet_compare, feed_dict={f1: tf1_x1, f2: tf1_x2})\n",
    "\n",
    "    print(tf1_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('pyt_tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0421650a8a5845f713c56c3ba4f436fc22593ad99b656f8436ea71c2ab26d6c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
